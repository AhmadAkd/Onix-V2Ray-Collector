#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Analytics for V2Ray Collector
ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ V2Ray Collector
"""

import json
import time
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter

@dataclass
class PerformanceMetrics:
    """Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
    total_configs: int
    working_configs: int
    failed_configs: int
    success_rate: float
    avg_latency: float
    median_latency: float
    protocol_distribution: Dict[str, int]
    country_distribution: Dict[str, int]
    latency_distribution: Dict[str, int]
    top_performing_protocols: List[Dict[str, Any]]
    top_performing_countries: List[Dict[str, Any]]

@dataclass
class TrendAnalysis:
    """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯"""
    period: str
    config_count_trend: str  # increasing, decreasing, stable
    success_rate_trend: str
    latency_trend: str
    top_growing_protocols: List[str]
    top_declining_protocols: List[str]

class AdvancedAnalytics:
    """ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø³ÛŒØ³ØªÙ…"""
    
    def __init__(self, data_dir: str = "analytics"):
        self.data_dir = data_dir
        self.historical_data: List[Dict] = []
        self.load_historical_data()
    
    def load_historical_data(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ"""
        try:
            with open(f"{self.data_dir}/historical_data.json", 'r', encoding='utf-8') as f:
                self.historical_data = json.load(f)
        except FileNotFoundError:
            self.historical_data = []
    
    def save_historical_data(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ"""
        import os
        os.makedirs(self.data_dir, exist_ok=True)
        
        with open(f"{self.data_dir}/historical_data.json", 'w', encoding='utf-8') as f:
            json.dump(self.historical_data, f, ensure_ascii=False, indent=2)
    
    def analyze_current_performance(self, working_configs: List, failed_configs: List) -> PerformanceMetrics:
        """ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ¹Ù„ÛŒ"""
        
        all_configs = working_configs + failed_configs
        total_configs = len(all_configs)
        working_count = len(working_configs)
        failed_count = len(failed_configs)
        success_rate = (working_count / total_configs * 100) if total_configs > 0 else 0
        
        # ØªØ­Ù„ÛŒÙ„ ØªØ£Ø®ÛŒØ±
        latencies = [config.latency for config in working_configs if config.latency > 0]
        avg_latency = statistics.mean(latencies) if latencies else 0
        median_latency = statistics.median(latencies) if latencies else 0
        
        # ØªÙˆØ²ÛŒØ¹ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§
        protocol_counts = Counter(config.protocol for config in all_configs)
        protocol_distribution = dict(protocol_counts)
        
        # ØªÙˆØ²ÛŒØ¹ Ú©Ø´ÙˆØ±Ù‡Ø§
        country_counts = Counter(config.country for config in working_configs)
        country_distribution = dict(country_counts)
        
        # ØªÙˆØ²ÛŒØ¹ ØªØ£Ø®ÛŒØ±
        latency_ranges = {
            "0-100ms": 0,
            "100-300ms": 0,
            "300-500ms": 0,
            "500-1000ms": 0,
            "1000ms+": 0
        }
        
        for latency in latencies:
            if latency <= 100:
                latency_ranges["0-100ms"] += 1
            elif latency <= 300:
                latency_ranges["100-300ms"] += 1
            elif latency <= 500:
                latency_ranges["300-500ms"] += 1
            elif latency <= 1000:
                latency_ranges["500-1000ms"] += 1
            else:
                latency_ranges["1000ms+"] += 1
        
        # Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ù„Ú©Ø±Ø¯
        protocol_performance = {}
        for protocol in protocol_distribution.keys():
            protocol_configs = [c for c in working_configs if c.protocol == protocol]
            if protocol_configs:
                protocol_latencies = [c.latency for c in protocol_configs if c.latency > 0]
                if protocol_latencies:
                    protocol_performance[protocol] = {
                        "count": len(protocol_configs),
                        "avg_latency": statistics.mean(protocol_latencies),
                        "success_rate": (len(protocol_configs) / protocol_distribution[protocol]) * 100
                    }
        
        top_performing_protocols = sorted(
            protocol_performance.items(),
            key=lambda x: (x[1]["success_rate"], -x[1]["avg_latency"]),
            reverse=True
        )[:5]
        
        # Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø´ÙˆØ±Ù‡Ø§
        country_performance = {}
        for country in country_distribution.keys():
            country_configs = [c for c in working_configs if c.country == country]
            if country_configs:
                country_latencies = [c.latency for c in country_configs if c.latency > 0]
                if country_latencies:
                    country_performance[country] = {
                        "count": len(country_configs),
                        "avg_latency": statistics.mean(country_latencies)
                    }
        
        top_performing_countries = sorted(
            country_performance.items(),
            key=lambda x: (-x[1]["count"], x[1]["avg_latency"])
        )[:5]
        
        return PerformanceMetrics(
            total_configs=total_configs,
            working_configs=working_count,
            failed_configs=failed_count,
            success_rate=success_rate,
            avg_latency=avg_latency,
            median_latency=median_latency,
            protocol_distribution=protocol_distribution,
            country_distribution=country_distribution,
            latency_distribution=latency_ranges,
            top_performing_protocols=[{"protocol": k, **v} for k, v in top_performing_protocols],
            top_performing_countries=[{"country": k, **v} for k, v in top_performing_countries]
        )
    
    def analyze_trends(self, days: int = 7) -> TrendAnalysis:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯Ù‡Ø§"""
        if len(self.historical_data) < 2:
            return TrendAnalysis(
                period=f"{days} days",
                config_count_trend="stable",
                success_rate_trend="stable",
                latency_trend="stable",
                top_growing_protocols=[],
                top_declining_protocols=[]
            )
        
        # ÙÛŒÙ„ØªØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø§Ø®ÛŒØ±
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_data = [
            d for d in self.historical_data 
            if datetime.fromisoformat(d['timestamp']) >= cutoff_date
        ]
        
        if len(recent_data) < 2:
            return TrendAnalysis(
                period=f"{days} days",
                config_count_trend="stable",
                success_rate_trend="stable",
                latency_trend="stable",
                top_growing_protocols=[],
                top_declining_protocols=[]
            )
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§
        config_counts = [d['total_configs'] for d in recent_data]
        config_trend = self._calculate_trend(config_counts)
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª
        success_rates = [d['success_rate'] for d in recent_data]
        success_trend = self._calculate_trend(success_rates)
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ØªØ£Ø®ÛŒØ±
        avg_latencies = [d['avg_latency'] for d in recent_data]
        latency_trend = self._calculate_trend(avg_latencies, reverse=True)  # Ú©Ù…ØªØ± = Ø¨Ù‡ØªØ±
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§
        protocol_trends = self._analyze_protocol_trends(recent_data)
        growing_protocols = [p for p, trend in protocol_trends.items() if trend > 0.1]
        declining_protocols = [p for p, trend in protocol_trends.items() if trend < -0.1]
        
        return TrendAnalysis(
            period=f"{days} days",
            config_count_trend=config_trend,
            success_rate_trend=success_trend,
            latency_trend=latency_trend,
            top_growing_protocols=growing_protocols[:3],
            top_declining_protocols=declining_protocols[:3]
        )
    
    def _calculate_trend(self, values: List[float], reverse: bool = False) -> str:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯"""
        if len(values) < 2:
            return "stable"
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÛŒØ¨ Ø®Ø· Ø±ÙˆÙ†Ø¯
        n = len(values)
        x = list(range(n))
        
        # Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ Ø³Ø§Ø¯Ù‡
        sum_x = sum(x)
        sum_y = sum(values)
        sum_xy = sum(x[i] * values[i] for i in range(n))
        sum_x2 = sum(x[i] ** 2 for i in range(n))
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)
        
        if reverse:
            slope = -slope
        
        if slope > 0.1:
            return "increasing"
        elif slope < -0.1:
            return "decreasing"
        else:
            return "stable"
    
    def _analyze_protocol_trends(self, data: List[Dict]) -> Dict[str, float]:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§"""
        if len(data) < 2:
            return {}
        
        protocol_trends = {}
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§
        for entry in data:
            for protocol, count in entry.get('protocol_distribution', {}).items():
                if protocol not in protocol_trends:
                    protocol_trends[protocol] = []
                protocol_trends[protocol].append(count)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ù‡Ø± Ù¾Ø±ÙˆØªÚ©Ù„
        result = {}
        for protocol, counts in protocol_trends.items():
            if len(counts) >= 2:
                trend = self._calculate_trend(counts)
                if trend == "increasing":
                    result[protocol] = 0.2
                elif trend == "decreasing":
                    result[protocol] = -0.2
                else:
                    result[protocol] = 0.0
        
        return result
    
    def generate_report(self, working_configs: List, failed_configs: List) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹"""
        
        # ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙØ¹Ù„ÛŒ
        current_performance = self.analyze_current_performance(working_configs, failed_configs)
        
        # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯Ù‡Ø§
        trends = self.analyze_trends()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ
        current_data = {
            "timestamp": datetime.now().isoformat(),
            "total_configs": current_performance.total_configs,
            "working_configs": current_performance.working_configs,
            "failed_configs": current_performance.failed_configs,
            "success_rate": current_performance.success_rate,
            "avg_latency": current_performance.avg_latency,
            "median_latency": current_performance.median_latency,
            "protocol_distribution": current_performance.protocol_distribution,
            "country_distribution": current_performance.country_distribution,
            "latency_distribution": current_performance.latency_distribution
        }
        
        self.historical_data.append(current_data)
        
        # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 30 Ø±ÙˆØ² Ø¯Ø§Ø¯Ù‡
        cutoff_date = datetime.now() - timedelta(days=30)
        self.historical_data = [
            d for d in self.historical_data 
            if datetime.fromisoformat(d['timestamp']) >= cutoff_date
        ]
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ
        self.save_historical_data()
        
        # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
        report = {
            "generated_at": datetime.now().isoformat(),
            "current_performance": asdict(current_performance),
            "trends": asdict(trends),
            "summary": {
                "overall_status": "excellent" if current_performance.success_rate > 80 else "good" if current_performance.success_rate > 60 else "needs_improvement",
                "key_insights": self._generate_key_insights(current_performance, trends),
                "recommendations": self._generate_recommendations(current_performance, trends)
            }
        }
        
        return report
    
    def _generate_key_insights(self, performance: PerformanceMetrics, trends: TrendAnalysis) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ"""
        insights = []
        
        if performance.success_rate > 80:
            insights.append(f"Ø¹Ø§Ù„ÛŒ! Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª {performance.success_rate:.1f}% Ø§Ø³Øª")
        elif performance.success_rate > 60:
            insights.append(f"Ø®ÙˆØ¨ØŒ Ø§Ù…Ø§ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª {performance.success_rate:.1f}% Ù‚Ø§Ø¨Ù„ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³Øª")
        else:
            insights.append(f"Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª {performance.success_rate:.1f}% Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯")
        
        if performance.avg_latency < 300:
            insights.append(f"ØªØ£Ø®ÛŒØ± Ù…ØªÙˆØ³Ø· {performance.avg_latency:.0f}ms Ø¹Ø§Ù„ÛŒ Ø§Ø³Øª")
        elif performance.avg_latency < 500:
            insights.append(f"ØªØ£Ø®ÛŒØ± Ù…ØªÙˆØ³Ø· {performance.avg_latency:.0f}ms Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ Ø§Ø³Øª")
        else:
            insights.append(f"ØªØ£Ø®ÛŒØ± Ù…ØªÙˆØ³Ø· {performance.avg_latency:.0f}ms Ø¨Ø§Ù„Ø§ Ø§Ø³Øª")
        
        top_protocol = max(performance.protocol_distribution.items(), key=lambda x: x[1])
        insights.append(f"Ù¾Ø±ÙˆØªÚ©Ù„ Ù…Ø­Ø¨ÙˆØ¨: {top_protocol[0]} Ø¨Ø§ {top_protocol[1]} Ú©Ø§Ù†ÙÛŒÚ¯")
        
        if trends.config_count_trend == "increasing":
            insights.append("Ø±ÙˆÙ†Ø¯ Ù…Ø«Ø¨Øª: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø³Øª")
        elif trends.config_count_trend == "decreasing":
            insights.append("Ù‡Ø´Ø¯Ø§Ø±: ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„ Ú©Ø§Ù‡Ø´ Ø§Ø³Øª")
        
        return insights
    
    def _generate_recommendations(self, performance: PerformanceMetrics, trends: TrendAnalysis) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recommendations = []
        
        if performance.success_rate < 70:
            recommendations.append("Ø§ÙØ²Ø§ÛŒØ´ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø§ Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§")
        
        if performance.avg_latency > 500:
            recommendations.append("Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØªØµØ§Ù„ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ Ú©Ù†Ø¯")
        
        if len(performance.protocol_distribution) < 3:
            recommendations.append("Ø§ÙØ²Ø§ÛŒØ´ ØªÙ†ÙˆØ¹ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§")
        
        if trends.latency_trend == "increasing":
            recommendations.append("Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù†Ø¯")
        
        if trends.success_rate_trend == "decreasing":
            recommendations.append("Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø­Ø°Ù Ù…Ù†Ø§Ø¨Ø¹ Ù†Ø§Ø³Ø§Ù„Ù…")
        
        return recommendations

# Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    from config_collector import V2RayConfig
    
    # Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    working_configs = [
        V2RayConfig("vmess", "test1.com", 443, "uuid1", latency=200, country="US"),
        V2RayConfig("vless", "test2.com", 443, "uuid2", latency=150, country="DE"),
        V2RayConfig("trojan", "test3.com", 443, "uuid3", latency=300, country="US"),
    ]
    
    failed_configs = [
        V2RayConfig("vmess", "bad1.com", 443, "uuid4", country="CN"),
        V2RayConfig("vless", "bad2.com", 443, "uuid5", country="RU"),
    ]
    
    # Ø§ÛŒØ¬Ø§Ø¯ ØªØ­Ù„ÛŒÙ„Ú¯Ø±
    analytics = AdvancedAnalytics()
    
    # ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´
    report = analytics.generate_report(working_configs, failed_configs)
    
    print("ğŸ“Š Advanced Analytics Report:")
    print("=" * 50)
    print(f"Success Rate: {report['current_performance']['success_rate']:.1f}%")
    print(f"Average Latency: {report['current_performance']['avg_latency']:.0f}ms")
    print(f"Total Configs: {report['current_performance']['total_configs']}")
    print(f"Working Configs: {report['current_performance']['working_configs']}")
    
    print("\nğŸ” Key Insights:")
    for insight in report['summary']['key_insights']:
        print(f"â€¢ {insight}")
    
    print("\nğŸ’¡ Recommendations:")
    for rec in report['summary']['recommendations']:
        print(f"â€¢ {rec}")
